{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial neural networks\n",
    "\n",
    "Author: Julian Li√üner\n",
    "\n",
    "For questions and feedback write a mail to: [lissner@mechbau.uni-stuttgart.de](mailto:lissner@mechbau.uni-stuttgart.de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "sys.path.extend( ['incomplete_functions', 'provided_functions'])\n",
    "import result_check as check\n",
    "import data_processing as process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Data preprocessing\n",
    "- before training a machine learning model the data should be pre processed\n",
    "- expert knowledge of the data will generally improve the models capabilities\n",
    "- different scalings have different effects, your knowledge can bring out the best\n",
    "- before starting to explore the ANN, the data has to be split into training data and the test set.\n",
    "\n",
    "--------\n",
    "__Task:__ Implement the `split_data` function in 'data_processing.py'. Apply it to split 20% of the data to the test set. Store the test set and the remaining training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice, \"split_data\" implemented correctly\n"
     ]
    }
   ],
   "source": [
    "raw_data = np.load( 'data/raw_data.npz' )\n",
    "x = raw_data['inputs' ]\n",
    "y = raw_data['outputs' ]\n",
    "check.split_data()\n",
    "\n",
    "test_part = #TODO\n",
    "x_train, y_train, x_test, y_test = process.split_data( x, y, test_part )\n",
    "\n",
    "np.savez_compressed( 'data/training_data.npz', x_train, y_train) \n",
    "np.savez_compressed( 'data/test_set.npz', x_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "- different features are usually defined on different scales\n",
    "- magnitude of the numbers govern significance for machine learning\n",
    "- input features should be scaled accordingly, matching their significance\n",
    "- in this case, equally important features are assumed\n",
    "- input and output may not have the same scaling\n",
    "- to shift data on a range from -1 to 1 the shift is given as<br>\n",
    "$\\quad \\hat y \\leftarrow y - \\text{min } y$<br>\n",
    "$\\quad \\hat y \\leftarrow 2\\, \\frac{\\hat y}{\\text{max } \\hat y} -1$\n",
    "- Note that each feature is given in a row\n",
    "\n",
    "--------\n",
    "__Task:__  Implement the `scale_data` function in 'data_processing.py' to scale each feature in the data on a range from -1 to +1. <br>\n",
    "Optional: Also implement the [0, +1] data scaling directly below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice, forward transform correctly implemented\n"
     ]
    }
   ],
   "source": [
    "scaletype = '-1,1'\n",
    "data = np.random.randn( 21, 1000) #21 features, 1000 samples\n",
    "#you may use the data for your own debugging\n",
    "check.scalings( scaletype, transformation='forward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the scaling should only be computed using the training data\n",
    "- the computed scaling is then be applied to the validation/test set\n",
    "\n",
    "---\n",
    "__Task:__ Compute the scaling using `x_train` and apply it to the `x_test`, inspect key values in each set. Implement the `unscale_data` and `scale_with_shifts` functions in 'data_processing.py'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaletype = '-1,1' \n",
    "#TODO = process.scale_data( #TODO )\n",
    "x_shift = process.scale_with_shifts( x_test, #TODO )\n",
    " \n",
    "check.scalings( scaletype)\n",
    "assert np.allclose( x_test, #TODO.( x_shift, #TODO ), 'unscaling wrongly implemented, values changed in the process' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "- the expert improves the model by their knowledge of the data\n",
    "- a nice way to explore unknown data is via plotting\n",
    "- the relation between input and output is the most relevant\n",
    "- in this data the first feature and the output value are highly correlated\n",
    "- outliers, distributions/histograms might also be of interest\n",
    "- inspection of the relationships in target values might also yield insights\n",
    "\n",
    "-----\n",
    "__Task__ - __Optional__: Plot the data to derive knowledge about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 3\n",
    "fig, axes = plt.subplots( 1, n_features, figsize=(16,6))\n",
    "for i in range( n_features):\n",
    "    axes[i].scatter( x_train[i], y_train[0] )\n",
    "    #optional TODO....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the machine learning model derives knowledge from data\n",
    "- good data thus enables good ML models\n",
    "- data related tasks are now finished and you can start to use your data\n",
    "\n",
    "\n",
    "-----\n",
    "__Task__: Implement the neural network in _ann_training.py_.<br>\n",
    "__Optional__: Do not use the any code template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
