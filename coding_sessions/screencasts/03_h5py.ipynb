{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# h5py introduction\n",
    "\n",
    "Author: Julian Li√üner<br>\n",
    "For questions and feedback please write a mail to: [lissner@mib.uni-stuttgart.de](mailto:lissner@mib.uni-stuttgart.de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import sys\n",
    "from datetime import date, datetime\n",
    "sys.path.append( 'submodules' )\n",
    "import read_h5 as read\n",
    "from general_functions import file_size, tic, toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system( 'rm *.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating hdf5 files \n",
    "- files are opened with permissions\n",
    "- `w` always creates a new file\n",
    "- `a` opens an existing file, creates if does not exist\n",
    "- `r` opens an existing file, can not write\n",
    "- `r+` opens an existing file, can write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "h5file = h5py.File( 'nonexistant_file.h5', 'r+' )\n",
    "#h5file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### Datasets and metadata in root folder ####\n",
      "\n",
      "#### Datasets stored in each folder ####\n",
      "\n",
      "content of folder: subfolder\n",
      "<HDF5 dataset \"data\": shape (69, 420), type \"<f4\">\n",
      "\n",
      "#### Metadata stored in each folder ####\n"
     ]
    }
   ],
   "source": [
    "h5file = h5py.File( 'nonexistant_file.h5', 'a' )\n",
    "#subfolder = h5file.create_group( 'arbitrary_name' )\n",
    "#subfolder.create_dataset( 'dset_0', data=np.arange( 5), compression='gzip', dtype='u1' )\n",
    "\n",
    "read.display_all_data( h5file)\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### Datasets and metadata in root folder ####\n",
      "\n",
      "#### Datasets stored in each folder ####\n",
      "\n",
      "#### Metadata stored in each folder ####\n"
     ]
    }
   ],
   "source": [
    "h5file = h5py.File( 'nonexistant_file.h5', 'w' )\n",
    "read.display_all_data( h5file)\n",
    "\n",
    "my_data = h5file.create_dataset( 'subfolder/data', shape=(69,420), compression='gzip' )\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to create dataset (no write intent on file)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\Qoutayba\\AppData\\Local\\Temp/ipykernel_6816/1610304882.py\"\u001b[0m, line \u001b[0;32m2\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    filecheck.create_dataset( 'some_data', data=np.arange(5) )\n",
      "  File \u001b[0;32m\"C:\\Users\\Qoutayba\\anaconda3\\lib\\site-packages\\h5py\\_hl\\group.py\"\u001b[0m, line \u001b[0;32m148\u001b[0m, in \u001b[0;35mcreate_dataset\u001b[0m\n    dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds)\n",
      "  File \u001b[0;32m\"C:\\Users\\Qoutayba\\anaconda3\\lib\\site-packages\\h5py\\_hl\\dataset.py\"\u001b[0m, line \u001b[0;32m137\u001b[0m, in \u001b[0;35mmake_new_dset\u001b[0m\n    dset_id = h5d.create(parent.id, name, tid, sid, dcpl=dcpl)\n",
      "  File \u001b[0;32m\"h5py\\_objects.pyx\"\u001b[0m, line \u001b[0;32m54\u001b[0m, in \u001b[0;35mh5py._objects.with_phil.wrapper\u001b[0m\n",
      "  File \u001b[0;32m\"h5py\\_objects.pyx\"\u001b[0m, line \u001b[0;32m55\u001b[0m, in \u001b[0;35mh5py._objects.with_phil.wrapper\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"h5py\\h5d.pyx\"\u001b[1;36m, line \u001b[1;32m87\u001b[1;36m, in \u001b[1;35mh5py.h5d.create\u001b[1;36m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m\u001b[1;31m:\u001b[0m Unable to create dataset (no write intent on file)\n"
     ]
    }
   ],
   "source": [
    "filecheck = h5py.File( 'nonexistant_file.h5', 'r' )\n",
    "filecheck.create_dataset( 'some_data', data=np.arange(5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( filecheck['subfolder/data'][:])\n",
    "filecheck.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- files need to  be open to access\n",
    "- permissions govern access type\n",
    "- if not careful files will be overwritten by `h5py`\n",
    "----------------\n",
    "----------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing data\n",
    "- datasets can be written without allocating memory\n",
    "- `h5py` sets pointers directly pointing on the hard drive\n",
    "- slight speedloss on partial writing\n",
    "- every data must have metadata\n",
    "- datatype specifies required storage of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "precompute_results = lambda x, y=3: x*y + 1\n",
    "partial_results = lambda n: np.arange( n) * np.random.randint( low=1, high=10)\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of file with only int dataset\n",
      "96.00 bytes\n",
      "size of file with also float dataset\n",
      "144.36 KiB\n"
     ]
    }
   ],
   "source": [
    "my_result = precompute_results( x=np.arange( 100000) )\n",
    "h5file = h5py.File( 'my_file.h5', 'w')\n",
    "result_group = h5file.create_group( 'results' )\n",
    "dataset = result_group.create_dataset( 'precomputed_results', data=my_result, compression='gzip', dtype=np.int16 )\n",
    "\n",
    "print( 'size of file with only int dataset' )\n",
    "print( file_size( 'my_file.h5' ) )\n",
    "\n",
    "result_group.create_dataset( 'big_results', data=my_result, compression='gzip', dtype=np.float64 )\n",
    "print( 'size of file with also float dataset' )\n",
    "print( file_size( 'my_file.h5' ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_group.attrs.update( dict( container_for='results', creation_code='explanation video' ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {'author':'lissner', 'date(yymmdd)':date.today().strftime(\"%YY:%MM%DD\"),\n",
    "            'time':datetime.now().strftime(\"%H:%M:%S\"), 'input parameter':'np.arange(1000)'}\n",
    "dataset.attrs.update( metadata) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_metadata( author='lissner'):\n",
    "    now = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    today = date.today().strftime(\"%YY/%MM/%DD\")\n",
    "    return { 'author':author, 'time':now, 'date(yymmdd)':today }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "#### partial write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "data_pointer = result_group.create_dataset( 'allocated_data', shape=(69,420), compression='gzip', dtype=np.int32 )\n",
    "data_pointer[:, 0] = 3.14141414\n",
    "print( data_pointer[:5,0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of my data pointer: <class 'numpy.ndarray'>\n",
      "type of my data pointer: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print( 'type of my data pointer:', type( data_pointer) )\n",
    "data_pointer = np.random.rand( 69, 420)\n",
    "print( 'type of my data pointer:', type( data_pointer) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of my data pointer: <class 'h5py._hl.dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "data_pointer = result_group[ 'allocated_data' ]\n",
    "print( 'type of my data pointer:', type( data_pointer) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing timer for this tag: looping 420 times\n",
      "looping 420 times -> elapsed time: 0.0670\n"
     ]
    }
   ],
   "source": [
    "n = data_pointer.shape[0] \n",
    "tic( 'looping {} times'.format( data_pointer.shape[-1] )) \n",
    "for i in range( 1, data_pointer.shape[-1] ):\n",
    "    data_pointer[ :, i ] = partial_results( n )    \n",
    "toc( 'looping {} times'.format( data_pointer.shape[-1] )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing timer for this tag: writing data directly\n",
      "writing data directly -> elapsed time: 0.0020\n"
     ]
    }
   ],
   "source": [
    "tic( 'writing data directly') \n",
    "data_pointer[:] = np.random.randint( low=0, high=9001, size=(69,420)) \n",
    "toc( 'writing data directly') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pointer.attrs.update( generic_metadata() )\n",
    "data_pointer.attrs.update( dict( input_parameter=n) )\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "#### Displaying elements of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results\n",
      "results/allocated_data\n",
      "results/big_results\n",
      "results/precomputed_results\n"
     ]
    }
   ],
   "source": [
    "h5file = h5py.File( 'my_file.h5', 'r') \n",
    "h5file.visit( print) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results <HDF5 group \"/results\" (3 members)>\n",
      "results/allocated_data <HDF5 dataset \"allocated_data\": shape (69, 420), type \"<i4\">\n",
      "results/big_results <HDF5 dataset \"big_results\": shape (100000,), type \"<f8\">\n",
      "results/precomputed_results <HDF5 dataset \"precomputed_results\": shape (100000,), type \"<i2\">\n"
     ]
    }
   ],
   "source": [
    "h5file.visititems( print) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata for the subfolder \"results\":\n",
      "container_for: results\n",
      "creation_code: explanation video\n"
     ]
    }
   ],
   "source": [
    "print( 'metadata for the subfolder \"results\":')\n",
    "for key, value in h5file['results'].attrs.items():\n",
    "    print( '{}: {}'.format( key, value) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5file.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "-----------------\n",
    "-----------------\n",
    "\n",
    "### Deleting datasets\n",
    "- not entire storage recovererd\n",
    "- can be done in python\n",
    "- handle to dataset required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some values of the dataset [ 1.  4.  7. 10. 13.]\n",
      "file of size with the dataset\n",
      "144.36 KiB\n",
      "!!! Can't acces dataset, does not exist\n",
      "file of size without the dataset\n",
      "144.36 KiB\n"
     ]
    }
   ],
   "source": [
    "h5file = h5py.File( 'my_file.h5', 'r+' )\n",
    "print( 'some values of the dataset', h5file[ 'results/big_results'][:5])\n",
    "print( 'file of size with the dataset' )\n",
    "print( file_size( 'my_file.h5' ) )\n",
    "\n",
    "del h5file[ 'results/big_results' ]\n",
    "\n",
    "try:\n",
    "    print( 'some values of the dataset', h5file[ 'results/big_results'][:5])\n",
    "except:\n",
    "    print( \"!!! Can't acces dataset, does not exist\")\n",
    "\n",
    "print( 'file of size without the dataset' ) \n",
    "print( file_size( 'my_file.h5' )  )\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## bugs bugs bugs, features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "h5file = h5py.File( 'tmpfile.h5', 'w')\n",
    "my_data = h5file.create_dataset( 'subfolder/random_data', data=np.arange(10) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "h5file = 'x'\n",
    "print( my_data[5] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to create file (unable to truncate a file which is already open)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\Qoutayba\\AppData\\Local\\Temp/ipykernel_6816/2972610346.py\"\u001b[0m, line \u001b[0;32m1\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    same_file = h5py.File( 'tmpfile.h5', 'w')\n",
      "  File \u001b[0;32m\"C:\\Users\\Qoutayba\\anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\"\u001b[0m, line \u001b[0;32m442\u001b[0m, in \u001b[0;35m__init__\u001b[0m\n    fid = make_fid(name, mode, userblock_size,\n",
      "  File \u001b[0;32m\"C:\\Users\\Qoutayba\\anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\"\u001b[0m, line \u001b[0;32m201\u001b[0m, in \u001b[0;35mmake_fid\u001b[0m\n    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)\n",
      "  File \u001b[0;32m\"h5py\\_objects.pyx\"\u001b[0m, line \u001b[0;32m54\u001b[0m, in \u001b[0;35mh5py._objects.with_phil.wrapper\u001b[0m\n",
      "  File \u001b[0;32m\"h5py\\_objects.pyx\"\u001b[0m, line \u001b[0;32m55\u001b[0m, in \u001b[0;35mh5py._objects.with_phil.wrapper\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"h5py\\h5f.pyx\"\u001b[1;36m, line \u001b[1;32m116\u001b[1;36m, in \u001b[1;35mh5py.h5f.create\u001b[1;36m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m\u001b[1;31m:\u001b[0m Unable to create file (unable to truncate a file which is already open)\n"
     ]
    }
   ],
   "source": [
    "same_file = h5py.File( 'tmpfile.h5', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "h5file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "same_file = h5py.File( 'tmpfile.h5', 'a')\n",
    "my_data = same_file['subfolder/random_data']\n",
    "my_data[0] = 9\n",
    "print( np.array( my_data) )\n",
    "same_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n"
     ]
    }
   ],
   "source": [
    "h5file = h5py.File( 'example_file.h5', 'w')\n",
    "data = h5file.create_dataset( 'subfolder/subsubfolder/data', shape=(10,10), dtype='u1')\n",
    "data[0,0] = -1\n",
    "print( data[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Not a dataset (not a dataset)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\Qoutayba\\AppData\\Local\\Temp/ipykernel_6816/3471371354.py\"\u001b[0m, line \u001b[0;32m2\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    data[-1,-1] = 255\n",
      "  File \u001b[0;32m\"h5py\\_objects.pyx\"\u001b[0m, line \u001b[0;32m54\u001b[0m, in \u001b[0;35mh5py._objects.with_phil.wrapper\u001b[0m\n",
      "  File \u001b[0;32m\"h5py\\_objects.pyx\"\u001b[0m, line \u001b[0;32m55\u001b[0m, in \u001b[0;35mh5py._objects.with_phil.wrapper\u001b[0m\n",
      "  File \u001b[0;32m\"C:\\Users\\Qoutayba\\anaconda3\\lib\\site-packages\\h5py\\_hl\\dataset.py\"\u001b[0m, line \u001b[0;32m913\u001b[0m, in \u001b[0;35m__setitem__\u001b[0m\n    selection = sel.select(self.shape, args, dataset=self)\n",
      "  File \u001b[0;32m\"C:\\Users\\Qoutayba\\anaconda3\\lib\\site-packages\\h5py\\_hl\\dataset.py\"\u001b[0m, line \u001b[0;32m413\u001b[0m, in \u001b[0;35mshape\u001b[0m\n    shape = self.id.shape\n",
      "  File \u001b[0;32m\"h5py\\h5d.pyx\"\u001b[0m, line \u001b[0;32m142\u001b[0m, in \u001b[0;35mh5py.h5d.DatasetID.shape.__get__\u001b[0m\n",
      "  File \u001b[0;32m\"h5py\\h5d.pyx\"\u001b[0m, line \u001b[0;32m143\u001b[0m, in \u001b[0;35mh5py.h5d.DatasetID.shape.__get__\u001b[0m\n",
      "  File \u001b[0;32m\"h5py\\_objects.pyx\"\u001b[0m, line \u001b[0;32m54\u001b[0m, in \u001b[0;35mh5py._objects.with_phil.wrapper\u001b[0m\n",
      "  File \u001b[0;32m\"h5py\\_objects.pyx\"\u001b[0m, line \u001b[0;32m55\u001b[0m, in \u001b[0;35mh5py._objects.with_phil.wrapper\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"h5py\\h5d.pyx\"\u001b[1;36m, line \u001b[1;32m299\u001b[1;36m, in \u001b[1;35mh5py.h5d.DatasetID.get_space\u001b[1;36m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m\u001b[1;31m:\u001b[0m Not a dataset (not a dataset)\n"
     ]
    }
   ],
   "source": [
    "h5file.close()\n",
    "data[-1,-1] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"dset_0\": shape (5,), type \"<i4\">"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5file = h5py.File( 'example_file.h5', 'r+')\n",
    "h5file['subfolder'].create_dataset( 'dset_0', data=np.arange(5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"dset_0\": shape (5,), type \"<i4\">\n",
      "[  0   1 999   3   4]\n",
      "[  0   1 999   3   4]\n"
     ]
    }
   ],
   "source": [
    "subfolder = h5file['subfolder']\n",
    "subfolder['dset_0'][2] = 999\n",
    "print( h5file['subfolder/dset_0'] )\n",
    "print( h5file['subfolder/dset_0'][:] )\n",
    "print( np.array( h5file['subfolder/dset_0'] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local variable [ 0 -1 -2 -3 -4]\n",
      "dataset [  0   1 999   3   4]\n"
     ]
    }
   ],
   "source": [
    "data = subfolder['dset_0']\n",
    "data = np.arange(5) * (-1)\n",
    "print( 'local variable', data )\n",
    "print( 'dataset', subfolder['dset_0'][:] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom entry\n"
     ]
    }
   ],
   "source": [
    "h5file.create_group( 'testgroup').attrs.update( dict( new='custom entry') )\n",
    "print( h5file[ 'testgroup'].attrs['new'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system( 'rm *.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
