{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `hdf5` files - primer\n",
    "\n",
    "Data Processing for Engineers and Scientists<br>\n",
    "Julian Lissner (lissner@mechbau.uni-stuttgart.de)<br>\n",
    "Felix Fritzen (fritzen@simtech.uni-stuttgart.de)\n",
    "\n",
    "## Scope\n",
    "Illustrate basic `hdf5` file operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "def convert_bytes( num):\n",
    "    \"\"\"\n",
    "    Convert bytes into the largest possible format with num > 1\n",
    "    The *iB refers to the binary file size format\n",
    "    Parameters:\n",
    "    -----------\n",
    "    num:    float\n",
    "            size of file given in machine format\n",
    "            (e.g. 1040101049204 [bytes]\n",
    "    Returns:\n",
    "    --------\n",
    "    num:    float\n",
    "            converted size to human readable format\n",
    "            (e.g. 1.04 TiB)\n",
    "    \n",
    "    \"\"\"\n",
    "    for x in ['bytes', 'KiB', 'MiB', 'GiB', 'TiB']:\n",
    "        if num < 1024.0:\n",
    "            return  \"%3.2f %s\" % (num, x)\n",
    "        num /= 1024.0\n",
    "\n",
    "\n",
    "def file_size( filename):\n",
    "    \"\"\"\n",
    "    Return the size of the given file in *iB format,\n",
    "    Requires the convertBytes function\n",
    "    Parameters:\n",
    "    -----------\n",
    "    filename:   string\n",
    "                full path to file \n",
    "    Returns:\n",
    "    --------\n",
    "    byte_size:  float\n",
    "                disc storage of the inspected file\n",
    "    \"\"\"\n",
    "    if os.path.isfile(filename):\n",
    "        file_info = os.stat(filename)\n",
    "        return convert_bytes(file_info.st_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating `hdf5` files\n",
    "\n",
    "- `h5py` interfaces python and hdf5 files\n",
    "- `hdf5` files have to be opened explicitly for either read or write access: <br>\n",
    "  **write** ( `w` ) and **append** ( `a` ) automatically create a file if it does not exist;<br>\n",
    "  **read** ( `r` ) will open a file for reading\n",
    "\n",
    "**Attention**\n",
    "- **write** ( `w` ) will always create a new, empty file (**overwriting existing files**)\n",
    "- trying to write to files opened with the **read** ( `r` ) flag throws an error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "### Create the `hdf5` file for data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stored values in the \"CourseInfo\" folder:\n",
      "ECTS:    6\n",
      "website: b'ilias3.uni-stuttgart.de/'\n"
     ]
    }
   ],
   "source": [
    "filename = 'DaPro_information.h5'\n",
    "DaPro = h5py.File( filename, 'w' )\n",
    "DaPro.create_group( 'ws_19-20' )\n",
    "previous_semester = DaPro.create_group( 'ws_20-21' )\n",
    "current_semester = DaPro.create_group( 'ws_21-22' )\n",
    "for semester in [ 'ws_19-20', 'ws_20-21', 'ws_21-22']:\n",
    "    DaPro[ semester].create_dataset( 'participants', data='Max Mustermann')\n",
    "    DaPro[ semester].create_dataset( 'slides', shape=(15,))\n",
    "\n",
    "general_info = DaPro.create_group( 'CourseInfo' )\n",
    "general_info.create_dataset( 'ECTS', data=6 ) \n",
    "DaPro[ 'CourseInfo'].create_dataset( 'website', data='ilias3.uni-stuttgart.de/' )\n",
    "\n",
    "print( 'stored values in the \"CourseInfo\" folder:')\n",
    "print( 'ECTS:   ', np.array( DaPro[ 'CourseInfo/ECTS']) )\n",
    "print( 'website:', np.array( DaPro[ 'CourseInfo/website']) )\n",
    "DaPro.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color='blue'> **Notes**</font>\n",
    "> - after closing, the file is inaccessible\n",
    "> - `visit/visititems(print)` display the file scructure \n",
    "> - different permissions allow different operations \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "### Accessing `hdf5` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has been closed, can not access it anymore\n",
      "\n",
      "structure of the created hdf5 file:\n",
      "CourseInfo\n",
      "CourseInfo/ECTS\n",
      "CourseInfo/website\n",
      "ws_19-20\n",
      "ws_19-20/participants\n",
      "ws_19-20/slides\n",
      "ws_20-21\n",
      "ws_20-21/participants\n",
      "ws_20-21/slides\n",
      "ws_21-22\n",
      "ws_21-22/participants\n",
      "ws_21-22/slides\n",
      "\n",
      "Unable to write in the opened hdf5 file\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    DaPro.visititems(print)\n",
    "except:\n",
    "    print( 'File has been closed, can not access it anymore' )\n",
    "\n",
    "DaPro = h5py.File( filename, 'r' )\n",
    "print( '\\nstructure of the created hdf5 file:' )\n",
    "DaPro.visit( print)\n",
    "print()\n",
    "\n",
    "try:\n",
    "    DaPro.create_group( 'ws_22-23' )\n",
    "except:\n",
    "    print( 'Unable to write in the opened hdf5 file' )\n",
    "DaPro.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "## Symbolic links within `hdf5` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdf5 structure\n",
      "A\n",
      "A/x\n",
      "A/y\n",
      "B\n"
     ]
    }
   ],
   "source": [
    "#h5file.close()\n",
    "filename = 'structure_example.h5'\n",
    "h5file = h5py.File( filename, 'w')\n",
    "main_folder = h5file.create_group( 'A') \n",
    "original_data = main_folder.create_dataset( 'y', data=np.arange(10) )\n",
    "\n",
    "main_folder['x'] = np.array( main_folder[ '/A/y'] ).copy()\n",
    "\n",
    "other_folder = h5file.create_group( 'B')\n",
    "other_folder['y'] = h5py.SoftLink( '/A/y' )\n",
    "other_folder['z'] = main_folder['y'] \n",
    "\n",
    "print('hdf5 structure' )\n",
    "h5file.visit( print) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links are not explicitely shown by `visititems`, but they exist, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_datasets( hdf5file):\n",
    "    print( 'original dataset:', np.array( h5file[ 'A/y']) )\n",
    "    print( 'copy:            ', np.array( h5file[ 'A/x']) )\n",
    "    print( 'softlink:        ', np.array( h5file[ 'B/y']) )\n",
    "    print( 'pointer:         ', np.array( h5file[ 'B/z']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing the original dataset in index 0\n",
      "original dataset: [5 1 2 3 4 5 6 7 8 9]\n",
      "copy:             [0 1 2 3 4 5 6 7 8 9]\n",
      "softlink:         [5 1 2 3 4 5 6 7 8 9]\n",
      "pointer:          [5 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print( 'changing the original dataset in index 0' )\n",
    "original_data[0] = 5\n",
    "display_datasets( h5file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing the copied dataset in index 1\n",
      "original dataset: [5 1 2 3 4 5 6 7 8 9]\n",
      "copy:             [0 9 2 3 4 5 6 7 8 9]\n",
      "softlink:         [5 1 2 3 4 5 6 7 8 9]\n",
      "pointer:          [5 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print( 'changing the copied dataset in index 1' )\n",
    "main_folder['x'][1] = 9\n",
    "display_datasets( h5file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing the softlink in index 2\n",
      "original dataset: [5 1 4 3 4 5 6 7 8 9]\n",
      "copy:             [0 9 2 3 4 5 6 7 8 9]\n",
      "softlink:         [5 1 4 3 4 5 6 7 8 9]\n",
      "pointer:          [5 1 4 3 4 5 6 7 8 9]\n",
      "changing the pointer in index 3\n",
      "original dataset: [5 1 4 2 4 5 6 7 8 9]\n",
      "copy:             [0 9 2 3 4 5 6 7 8 9]\n",
      "softlink:         [5 1 4 2 4 5 6 7 8 9]\n",
      "pointer:          [5 1 4 2 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print( 'changing the softlink in index 2' )\n",
    "h5file[ 'B/y'][2] = 4\n",
    "display_datasets( h5file)\n",
    "\n",
    "print( 'changing the pointer in index 3' )\n",
    "pointer = other_folder['z']\n",
    "pointer[3] = 2\n",
    "display_datasets( h5file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "### Datatypes\n",
    "\n",
    "**Datatypes** are useful when using specific datatypes (e.g. `int`, `float`, `char` (which equals `np.uint8`)) are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stored float values:\n",
      " [[1.  0.  0.  ... 0.  0.  1.3]\n",
      " [0.  0.  0.  ... 0.  0.  0. ]\n",
      " [0.  0.  0.  ... 0.  0.  0. ]\n",
      " ...\n",
      " [0.  0.  0.  ... 0.  0.  0. ]\n",
      " [0.  0.  0.  ... 0.  0.  0. ]\n",
      " [1.  0.  0.  ... 0.  0.  1.5]]\n",
      "stored int values:\n",
      " [[1 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 1]]\n",
      "\n",
      "size of the file containing float values:\n",
      "1.00 MiB\n",
      "size of the file containing int values:\n",
      "130.00 KiB\n"
     ]
    }
   ],
   "source": [
    "data = np.zeros( (512, 256) )\n",
    "data[0,0] = 1\n",
    "data[0,-1] = 1.3\n",
    "data[-1,0] = 1\n",
    "data[-1,-1] = 1.5\n",
    "\n",
    "float_file = h5py.File( 'float_storage.h5', 'w')\n",
    "float_file.create_dataset( 'float_values', data=data) #default dtype is np.int64\n",
    "print( 'stored float values:\\n',  float_file['float_values'][:] )\n",
    "float_file.close()\n",
    "\n",
    "int_file = h5py.File( 'int_storage.h5', 'w')\n",
    "int_file.create_dataset( 'int_values', data=data, dtype=np.int8)\n",
    "print( 'stored int values:\\n',  int_file['int_values'][:] )\n",
    "int_file.close()\n",
    "print( '\\nsize of the file containing float values:')\n",
    "print( file_size( 'float_storage.h5' ))\n",
    "print( 'size of the file containing int values:')\n",
    "print( file_size( 'int_storage.h5' ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----- \n",
    "### Compression\n",
    "- lossless compression (i.e. *not* like `MP3` or `JPEG`)\n",
    "- leads to slight decrease in r/w speed\n",
    "- generally (significant) storage savings (depending on the actual data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size with only compressed sparse dataset: 6.38 KiB\n",
      "total size with pattern dataset:\t 157.14 KiB\n",
      "total size with random dataset: \t 1.10 MiB\n"
     ]
    }
   ],
   "source": [
    "sparse_data = np.zeros( (512, 256) )\n",
    "sparse_data[ [0, 0,-1, -1], [0,-1,0,-1]] = 2\n",
    "pattern_data = np.arange( 512*256).reshape( 512, 256)\n",
    "random_data = np.random.rand( 512, 256)\n",
    "\n",
    "compression_file = h5py.File( 'compressions.h5', 'w')\n",
    "compression_file.create_dataset( 'sparse', data=sparse_data, compression='gzip')\n",
    "print( 'size with only compressed sparse dataset:', file_size( 'compressions.h5') )\n",
    "compression_file.create_dataset( 'pattern', data=pattern_data, compression='gzip')\n",
    "print( 'total size with pattern dataset:\\t', file_size( 'compressions.h5') )\n",
    "compression_file.create_dataset( 'random', data=random_data, compression='gzip')\n",
    "print( 'total size with random dataset: \\t', file_size( 'compressions.h5') )\n",
    "compression_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "### Metadata/Attributes\n",
    "- metadata is data describing data (e.g. author, creation date/time, ...)\n",
    "- groups and datasets can both have metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata attached to the group \"laboratory_results\":\n",
      " {'date': '12.12.12', 'researcher': 'Max Muster', 'time': '12:12am'}\n",
      "metadata attached to measurement_0: {'pressure': '988 hPa', 'temperature': '32.15 celcius'}\n",
      "metadata attached to measurement_1: {'pressure': '988 hPa', 'temperature': '32.25 celcius'}\n",
      "metadata attached to measurement_2: {'pressure': '988 hPa', 'temperature': '32.58 celcius'}\n"
     ]
    }
   ],
   "source": [
    "h5file = h5py.File( 'labeled_data.h5', 'w' )\n",
    "measurements = h5file.create_group( 'laboratory_results' )\n",
    "measurements.attrs.update( dict( date='12.12.12', time='12:12am', researcher='Max Muster') )\n",
    "datasets = ['measurement_0', 'measurement_1', 'measurement_2']\n",
    "\n",
    "for dataset in datasets:\n",
    "    current_data = np.random.randint( 0,64, size=(32, 32, 32)) \n",
    "    measurements.create_dataset( dataset, data=current_data, compression='gzip' )\n",
    "    metadata = measurements[dataset].attrs\n",
    "    metadata[ 'temperature'] = '{:2.2f} celcius'.format( 32 + np.random.randn() )\n",
    "    metadata[ 'pressure'] = '{} hPa'.format( 987+ np.random.randint( -2, 3) )\n",
    "\n",
    "print( 'metadata attached to the group \"laboratory_results\":\\n', dict( measurements.attrs) )\n",
    "for dataset in datasets:\n",
    "    print( 'metadata attached to {}: {}'.format( dataset, dict( measurements[dataset].attrs )) )\n",
    "h5file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleanup (free disc space)\n",
    "import os\n",
    "os.system( 'rm DaPro_information.h5     ' )\n",
    "os.system( 'rm structure_example.h5     ' )\n",
    "os.system( 'rm float_storage.h5   ' )\n",
    "os.system( 'rm int_storage.h5     ' )\n",
    "os.system( 'rm compressions.h5    ' )\n",
    "os.system( 'rm labeled_data.h5    ' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
#####