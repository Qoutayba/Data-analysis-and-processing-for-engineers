{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Image processing\n",
    "by Shadi Alameddin <alameddin@mib.uni-stuttgart.de>, January 2022\n",
    "\n",
    "additional material for the course _Data Processing for Engineers and Scientists_ at the University of Stuttgart\n",
    "\n",
    "## Content\n",
    "\n",
    "### Part 1: image manipulation\n",
    "- How to read and write images\n",
    "- Manipulate individual pixels of an image\n",
    "- Convert RGB image to a grayscale one\n",
    "\n",
    "### Part 2: image segmentation\n",
    "- Non-binary segmentation\n",
    "- Smoothing filters\n",
    "- Binary segmentation\n",
    "\n",
    "### Part 3: binary image manipulation\n",
    "- Morphological operations\n",
    "- Circle detection algorithm\n",
    "- Extract sttistical infromation from an image\n",
    "- Extra: segmentation and crack detection\n",
    "\n",
    "### Optional part:\n",
    "- Improve the output of the circle detection algorithm\n",
    "- Segment the full image instead of the sample we used here\n",
    "- Use more than one morphological operation to achieve a better result\n",
    "- Try to isolate the cracks in the particles\n",
    "- Elaborate on the provided examples to build a basic __traffic-sign recognition system__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Part 1: loading and manipulating images\n",
    "__given__: an RGB image file with pixels in $$ \\mathbb{A} = \\{0,\\cdots,255\\}^3$$\n",
    "- load it into Python (use `matplotlib` and `cv2`: OpenCV)\n",
    "- visualise it\n",
    "- delete some rows or columns of the image\n",
    "- compress it to a grayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "RPdD3SIRiPnO",
    "outputId": "ca1da08c-6441-4960-b44e-c0ca4b1c0cc3",
    "pycharm": {
     "is_executing": true,
     "name": "#%% import libararies & alter plotting options\n"
    }
   },
   "outputs": [],
   "source": [
    "# pip install opencv-python\n",
    "import numpy as np\n",
    "import cv2 as cv \n",
    "from matplotlib import rc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['DejaVu Sans'], 'size':16})\n",
    "plt.rcParams['xtick.bottom'] = plt.rcParams['xtick.labelbottom'] = False\n",
    "plt.rcParams['xtick.top'] = plt.rcParams['xtick.labeltop'] = True\n",
    "plt.rcParams['axes.grid']=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "9YNijzSYisrN",
    "outputId": "42349cc1-c19d-452b-bd98-195fd0322b23"
   },
   "outputs": [],
   "source": [
    "# read an image in RGB format\n",
    "original_image_rgb = plt.imread('micrograph.tif')\n",
    "\n",
    "fig, ax= plt.subplots(1,3,figsize=[16,4])\n",
    "ax[0].imshow(original_image_rgb)\n",
    "ax[0].set_title('Original RGB image')\n",
    "\n",
    "# recall that (0,0) is on the top-left\n",
    "corrupted_image = np.copy(original_image_rgb)\n",
    "corrupted_image[750:800,:,:]=0\n",
    "corrupted_image[:,2000:2050,:]=[255,0,0]\n",
    "ax[1].imshow(corrupted_image)\n",
    "ax[1].set_title('Manipulated image')\n",
    "\n",
    "original_image_gray = cv.cvtColor(original_image_rgb,cv.COLOR_RGB2GRAY)\n",
    "ax[2].imshow(original_image_gray,cmap=\"gray\")\n",
    "ax[2].set_title('Grayscale representation')\n",
    "\n",
    "print(f'matrix shape of the original image{original_image_rgb.shape}')\n",
    "print(f'imported image has {original_image_rgb.shape[0]} pixels vertically and {original_image_rgb.shape[1]} horizontally')\n",
    "print(f'minumum and maximum values in the original matrix: {original_image_rgb.min(),original_image_rgb.max()}')\n",
    "print(f'matrix shape of the grayscale image {original_image_gray.shape}')\n",
    "print(f'minumum and maximum values in the grayscale matrix: {original_image_gray.min(),original_image_gray.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: image segmentation\n",
    "- crop a small \"_representative_\" sample of the grayscale image\n",
    "- look at the values of each pixel\n",
    "- set a \"_reasonable_\" threshold -> first segmented version (non-binary segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "yrange = np.arange(50,350)[:,None]\n",
    "xrange = np.arange(50,350)[None,:]\n",
    "image=original_image_rgb[yrange,xrange,:]\n",
    "image_gray=original_image_gray[yrange,xrange]\n",
    "\n",
    "fig, ax= plt.subplots(1,3,figsize=[16,4])\n",
    "ax[0].set_title('Sample to be investigated')\n",
    "ax[0].imshow(image_gray,cmap=\"gray\")\n",
    "\n",
    "ax[1].set_title('Pixel intensity histogram')\n",
    "ax[1].hist(image_gray.flatten())\n",
    "ax[1].set_box_aspect(1)\n",
    "ax[1].set_xlabel('gray level')\n",
    "ax[1].set_ylabel('number of pixels')\n",
    "\n",
    "# TODO: look at cv.THRESH_BINARY\n",
    "segmented_image_gray = np.copy(image_gray)\n",
    "rng = segmented_image_gray<=175\n",
    "segmented_image_gray[rng]=0\n",
    "ax[2].set_title('Non-binary segmented image')\n",
    "ax[2].imshow(segmented_image_gray,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- smooth the image\n",
    "- convert the image to a binary segmented one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "kernel_size = 5\n",
    "# segmented_image_gray = cv.GaussianBlur(image,(kernel_size,kernel_size),0)\n",
    "smoothed_image = cv.medianBlur(image,kernel_size)\n",
    "fig, ax= plt.subplots(1,3,figsize=[16,4])\n",
    "ax[0].set_title('Smoothed image')\n",
    "ax[0].imshow(smoothed_image,cmap=\"gray\")\n",
    "\n",
    "segmented_image_gray = cv.cvtColor(smoothed_image,cv.COLOR_RGB2GRAY)\n",
    "segmented_image_gray[segmented_image_gray<=185]=0\n",
    "segmented_image_gray[segmented_image_gray>=195]=255\n",
    "ax[1].set_title('Non-binary segmentation')\n",
    "ax[1].imshow(segmented_image_gray,cmap=\"gray\")\n",
    "\n",
    "binary_image = segmented_image_gray\n",
    "rng=segmented_image_gray>=186\n",
    "segmented_image_gray[rng]= 1\n",
    "segmented_image_gray[~rng] = 0\n",
    "ax[2].set_title('Binary segmentation')\n",
    "ax[2].imshow(binary_image,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check color values in each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax= plt.subplots(1,3,figsize=[16,4])\n",
    "ax[0].hist(image[...,0].flatten(),color='red')\n",
    "ax[0].set_title('Red intensity histogram')\n",
    "ax[0].set_box_aspect(1)\n",
    "ax[0].set_xlabel('gray level')\n",
    "ax[0].set_ylabel('number of pixels')\n",
    "\n",
    "ax[1].hist(image[...,1].flatten(),color='green')\n",
    "ax[1].set_title('Green intensity histogram')\n",
    "ax[1].set_box_aspect(1)\n",
    "ax[1].set_xlabel('gray level')\n",
    "ax[1].set_ylabel('number of pixels')\n",
    "\n",
    "ax[2].hist(image[...,2].flatten(),color='blue')\n",
    "ax[2].set_title('Blue intensity histogram')\n",
    "ax[2].set_box_aspect(1)\n",
    "ax[2].set_xlabel('gray level')\n",
    "ax[2].set_ylabel('number of pixels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- enhance image contrast\n",
    "- what about making only one dominant color in each pixel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% Use color information\n"
    }
   },
   "outputs": [],
   "source": [
    "modified_image = np.copy(image)\n",
    "modified_image[modified_image<=175] = 0\n",
    "fig, ax= plt.subplots(1,3,figsize=[16,4])\n",
    "ax[0].set_title('Image without redundant info')\n",
    "ax[0].imshow(modified_image)\n",
    "\n",
    "flatten_image = image.reshape(-1,3)\n",
    "flatten_color_segmented_image = np.zeros_like(flatten_image)\n",
    "idx = np.argmax(flatten_image,axis=1)\n",
    "flatten_color_segmented_image[idx==0]=[255,0,0]\n",
    "flatten_color_segmented_image[idx==1]=[0,255,0]\n",
    "flatten_color_segmented_image[idx==2]=[0,0,255]\n",
    "color_segmented_image = flatten_color_segmented_image.reshape(image.shape)\n",
    "ax[1].set_title('Dominant color segmentation')\n",
    "ax[1].imshow(color_segmented_image)\n",
    "\n",
    "binary_image = np.copy(flatten_color_segmented_image)\n",
    "binary_image[idx==2]=0\n",
    "binary_image[idx!=2]=1\n",
    "binary_image = np.mean(binary_image.reshape(image.shape),axis=2)\n",
    "ax[2].imshow(binary_image,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- filtering accounts for nonlocal information $\\blacktriangleright$ thresholding of the filtered image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax= plt.subplots(1,3,figsize=[16,4])\n",
    "ax[0].set_title('Image without redundant info')\n",
    "ax[0].imshow(modified_image)\n",
    "\n",
    "kernel_size = 17\n",
    "color_segmented_image2 = cv.medianBlur(color_segmented_image,kernel_size)\n",
    "ax[1].set_title('Dominant color segmentation')\n",
    "ax[1].imshow(color_segmented_image2)\n",
    "\n",
    "binary_image = cv.cvtColor(color_segmented_image2,cv.COLOR_RGB2GRAY)\n",
    "rng = (binary_image>15) & (binary_image<30)\n",
    "binary_image[rng]=0\n",
    "binary_image[~rng]=1\n",
    "ax[2].set_title('Segmented image')\n",
    "ax[2].imshow(binary_image,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is also possible to use region labeling to get obtain a segmented version of the provided image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Part 3: binary image manipulation\n",
    "\n",
    "Morphological operations:\n",
    "- Dilation - grow image regions [set pixel to max (white) within a box]\n",
    "- Erosion - shrink image regions [set pixel to min (black) within a box]\n",
    "- Opening - structured removal of image region boundary pixels [erosion followed by a dilation, remove white dots]\n",
    "- Closing - structured filling in of image region boundary pixels [a dilation followed by an erosion, remove black dots]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "binary_image2 = np.bitwise_not(binary_image)\n",
    "# kernel = np.ones((3, 3), np.uint8)/9\n",
    "kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE,(5,5))\n",
    "\n",
    "itr = 4\n",
    "image_dialated = cv.morphologyEx(binary_image2, cv.MORPH_DILATE, kernel, iterations=itr)\n",
    "image_eroded = cv.morphologyEx(binary_image2, cv.MORPH_ERODE, kernel, iterations=itr)\n",
    "image_opening = cv.morphologyEx(binary_image2, cv.MORPH_OPEN, kernel, iterations=itr)\n",
    "image_closing = cv.morphologyEx(binary_image2, cv.MORPH_CLOSE, kernel, iterations=itr)\n",
    "\n",
    "fig, ax= plt.subplots(2,2,figsize=[12,12])\n",
    "ax[0,0].set_title('Dialated image')\n",
    "ax[0,0].imshow(image_dialated)\n",
    "ax[0,1].set_title('Eroded image')\n",
    "ax[0,1].imshow(image_eroded)\n",
    "ax[1,0].set_title('Closed image')\n",
    "ax[1,0].imshow(image_closing)\n",
    "ax[1,1].set_title('Opened image')\n",
    "ax[1,1].imshow(image_opening)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color='red'>**NOTE**</font>\n",
    "> * Iterative application of opening and closing multiple times with the same kernel should be identical to applying them once. In other words, the morphological opening and closing are idempotent [Statistical Analysis of Microstructures in Materials Science by Ohser and Mücklich]. However, we see a different result using OpenCV \"morphologyEx\" function.\n",
    "> * If you execute \"help(cv.morphologyEx)\" you'll find the following comment:\n",
    "<font color='gray'>\n",
    "@note The number of iterations is the number of times erosion or dilatation operation will be applied. For instance, an opening operation (#MORPH_OPEN) with two iterations is equivalent to apply successively: erode -> erode -> dilate -> dilate (and not erode -> dilate -> erode -> dilate).\n",
    "</font>\n",
    "> * Opening and closing operations can also be tested with:\n",
    "```open(open(img,k),k) == open(img,k)?``` and ```close(close(img,k),k) == close(img,k)?```.\n",
    "Both should be satisfied unless the implmentation doesn't try to replicate the theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Circle detection algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% synthetic image\n"
    }
   },
   "outputs": [],
   "source": [
    "img_255 = np.array(image_eroded,dtype=np.uint8)\n",
    "synthetic_image = np.zeros_like(image_eroded)\n",
    "\n",
    "circles = cv.HoughCircles(img_255,cv.HOUGH_GRADIENT,1.0,50,param1=1e-6,param2=12,minRadius=3,maxRadius=80)\n",
    "circles = np.uint16(circles)\n",
    "\n",
    "for i in circles[0,:]:\n",
    "    synthetic_image = cv.circle(synthetic_image, (i[0],i[1]), i[2], 1, -1)\n",
    "\n",
    "fig, ax= plt.subplots(1,2,figsize=[12,8])\n",
    "ax[0].set_title('Input binary image')\n",
    "ax[0].imshow(img_255)\n",
    "ax[1].set_title('Synthetic image')\n",
    "ax[1].imshow(synthetic_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Statistical information from an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% Statistics\n"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "\n",
    "def extract_plot_statistics(h_stripe,v_stripe,sg_window,sg_order):\n",
    "    h_vol_av=[]\n",
    "    v_vol_av=[]\n",
    "    reinforcement_depth = []\n",
    "\n",
    "    for i in np.arange(0,synthetic_image.shape[0] - h_stripe):\n",
    "        id_range = range(i, i + h_stripe)\n",
    "        h_vol_av.append( np.count_nonzero(synthetic_image[id_range,:]) / synthetic_image[id_range,:].size)\n",
    "\n",
    "    for i in np.arange(0,synthetic_image.shape[1] - v_stripe):\n",
    "        id_range = range(i, i + v_stripe)\n",
    "        v_vol_av.append( np.count_nonzero(synthetic_image[:,id_range]) / synthetic_image[:,id_range].size)\n",
    "\n",
    "        reinforcement_depth.append(np.nonzero(np.sum(synthetic_image[:,id_range],axis=1))[-1][-1] if np.sum(synthetic_image[:,id_range]) > 0 else 0)\n",
    "   \n",
    "    smotthed_h_vol_av = savgol_filter(h_vol_av, sg_window, sg_order)\n",
    "    smotthed_v_vol_av = savgol_filter(v_vol_av, sg_window, sg_order)\n",
    "    smoothed_reinforcement_depth = savgol_filter(reinforcement_depth, sg_window, sg_order)\n",
    "\n",
    "    smotthed_h_vol_av[smotthed_h_vol_av<=0] = 0\n",
    "    smotthed_v_vol_av[smotthed_v_vol_av<0] = 0\n",
    "    smoothed_reinforcement_depth[smoothed_reinforcement_depth<0] = 0\n",
    "\n",
    "    fig, ax= plt.subplots(2,3,figsize=[16,10])\n",
    "    ax[0,0].set_visible(False)\n",
    "    ax[0,2].set_visible(False)\n",
    "\n",
    "    ax[1,0].plot(h_vol_av,range(len(h_vol_av)),'k', linestyle='--',linewidth=2)\n",
    "    ax[1,0].plot(smotthed_h_vol_av,range(len(h_vol_av)),'k',linewidth=3)\n",
    "    ax[1,0].invert_xaxis()\n",
    "    ax[1,0].invert_yaxis()\n",
    "    ax[1,0].set_box_aspect(1)\n",
    "    # ax[1,0].set_title('vol frac per row (depth)')\n",
    "    ax[1,0].set_xlabel('volume fraction w.r.t. depth[-]')\n",
    "    ax[1,0].xaxis.set_label_position(\"top\")\n",
    "    \n",
    "    ax[0,1].plot(range(len(v_vol_av)),v_vol_av,'k', linestyle='--',linewidth=2)\n",
    "    ax[0,1].plot(range(len(v_vol_av)),smotthed_v_vol_av,'k',linewidth=3)\n",
    "    ax[0,1].set_title('vol frac per column')\n",
    "    ax[0,1].set_ylabel('volume fraction [-]')\n",
    "    ax[0,1].set_box_aspect(1)\n",
    "\n",
    "    ax[1,1].imshow(synthetic_image)\n",
    "    ax[1,1].set_xticks([])\n",
    "    ax[1,1].set_yticks([])\n",
    "\n",
    "    ax[1,2].plot(reinforcement_depth,'k', linestyle='--',linewidth=2)\n",
    "    ax[1,2].plot(smoothed_reinforcement_depth,'k',linewidth=3)\n",
    "    ax[1,2].set_title('reinforcement depth')\n",
    "    ax[1,2].set_ylabel('depth [pixels]')\n",
    "    ax[1,2].invert_yaxis()\n",
    "    ax[1,2].set_box_aspect(1)\n",
    "    ax[1,2].yaxis.tick_right()\n",
    "    ax[1,2].yaxis.set_label_position(\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact, widgets\n",
    "\n",
    "interact(extract_plot_statistics,h_stripe=widgets.IntSlider(min=1, max=29, step=1, value=1),\n",
    "         v_stripe=widgets.IntSlider(min=1, max=29, step=1, value=1),\n",
    "         sg_window=widgets.IntSlider(min=3, max=50, step=2, value=3),\n",
    "         sg_order=widgets.IntSlider(min=1, max=5, step=1, value=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra: segmentation and crack detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "# get image and read properties\n",
    "\n",
    "# rgb_image = plt.imread('micrograph.tif')[:800,:800]\n",
    "rgb_image = plt.imread('micrograph.tif')[:1750,:2200]\n",
    "\n",
    "print('properties of original image: ')\n",
    "print(f'matrix_shape {rgb_image.shape}')\n",
    "print(f'resolution {rgb_image.shape[0]} x {rgb_image.shape[1]}')\n",
    "\n",
    "# contrast improvement by enhancing dark pixels from the background\n",
    "gray_image = cv.cvtColor(rgb_image, cv.COLOR_BGR2GRAY)\n",
    "gray_image[gray_image<180]=0\n",
    "\n",
    "# Image blurring -> image smoothing & noise removal\n",
    "blured_image = cv.medianBlur(rgb_image, 9)\n",
    "# blured_image = cv.bilateralFilter(rgb_image, 5,50,50)\n",
    "\n",
    "\n",
    "fig, ax= plt.subplots(1,3,figsize=[16,4])    \n",
    "ax[0].imshow(rgb_image)\n",
    "ax[1].imshow(gray_image,cmap='gray')\n",
    "ax[2].imshow(blured_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_image = np.copy(rgb_image)\n",
    "modified_image[modified_image<=175] = 0\n",
    "fig, ax= plt.subplots(1,3,figsize=[16,4])\n",
    "ax[0].set_title('Image without redundant info')\n",
    "ax[0].imshow(modified_image)\n",
    "\n",
    "flatten_image = rgb_image.reshape(-1,3)\n",
    "flatten_color_segmented_image = np.zeros_like(flatten_image)\n",
    "idx = np.argmax(flatten_image,axis=1)\n",
    "flatten_color_segmented_image[idx==0]=[255,0,0]\n",
    "flatten_color_segmented_image[idx==1]=[0,255,0]\n",
    "flatten_color_segmented_image[idx==2]=[0,0,255]\n",
    "color_segmented_image = flatten_color_segmented_image.reshape(rgb_image.shape)\n",
    "\n",
    "kernel_size = 17\n",
    "color_segmented_image = cv.medianBlur(color_segmented_image,kernel_size)\n",
    "ax[1].set_title('Dominant color segmentation')\n",
    "ax[1].imshow(color_segmented_image)\n",
    "\n",
    "binary_image = cv.cvtColor(color_segmented_image,cv.COLOR_RGB2GRAY)\n",
    "rng = (binary_image>15) & (binary_image<30)\n",
    "binary_image[rng]=1\n",
    "binary_image[~rng]=0\n",
    "ax[2].set_title('Segmented image')\n",
    "ax[2].imshow(binary_image,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax= plt.subplots(1,3,figsize=[16,4])\n",
    "ax[0].imshow(gray_image,cmap=\"gray\")\n",
    "ax[1].imshow(binary_image,cmap=\"gray\")\n",
    "ax[2].imshow(binary_image * gray_image,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax= plt.subplots(1,3,figsize=[16,4])\n",
    "\n",
    "kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE,(5,5))\n",
    "binary_image_eroded = cv.morphologyEx(binary_image, cv.MORPH_ERODE, kernel, iterations=8)\n",
    "ax[0].imshow(binary_image_eroded,cmap=\"gray\")\n",
    "\n",
    "\n",
    "laplacian = cv.Laplacian(gray_image,cv.CV_16S,ksize=9)\n",
    "ax[1].imshow(laplacian)\n",
    "\n",
    "cracks_image=laplacian*binary_image_eroded\n",
    "ax[2].imshow(cracks_image,cmap=\"gray\")\n",
    "\n",
    "rng = (cracks_image<15e3) \n",
    "cracks_image[rng]=255\n",
    "cracks_image[~rng]=0\n",
    "ax[2].imshow(cracks_image,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax= plt.subplots(1,3,figsize=[16,4])\n",
    "\n",
    "\n",
    "n=5\n",
    "kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE,(n,n))\n",
    "\n",
    "dialated = cv.morphologyEx(cracks_image, cv.MORPH_ERODE, kernel, iterations=1)\n",
    "ax[0].imshow(dialated,cmap=\"gray\")\n",
    "\n",
    "opened = cv.morphologyEx(dialated, cv.MORPH_OPEN, kernel, iterations=2)\n",
    "ax[1].imshow(opened,cmap=\"gray\")\n",
    "\n",
    "n=3\n",
    "kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE,(n,n))\n",
    "closed = cv.morphologyEx(opened, cv.MORPH_CLOSE, kernel, iterations=3)\n",
    "ax[2].imshow(closed,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax= plt.subplots(1,2,figsize=[18,6])\n",
    "ax[0].imshow(rgb_image)\n",
    "\n",
    "rgb_cracks = np.copy(rgb_image)\n",
    "rgb_cracks[closed[:,:]==0]=[255,0,0]\n",
    "ax[1].imshow(rgb_cracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "image_segmentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nteract": {
   "version": "0.26.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
