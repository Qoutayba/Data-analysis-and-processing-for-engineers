{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Confidence interval estimation**\n",
    "\n",
    "by Felix Fritzen (fritzen@simtech.uni-stuttgart.de)\n",
    "\n",
    "additional material for the course _Data processing for engineers and scientists_ at the University of Stuttgart\n",
    "\n",
    "\n",
    "## **Objective**\n",
    "Given $n$ data samples stored in a vector $\\underline{y}\\in\\mathbb{R}^n$ of samples drawn from IID random variables $Y_1, \\dots, Y_n$. We are interested in a **quantity of interest (QOI)** of the underlying i.i.d. random variables  $Y_1, Y_2, \\dots, Y_n$ with standard deviation $\\sigma_y$.\n",
    "\n",
    "**Point estimators** provide single values for the QOI, for instance **maximum likelihood estimation (MLE)**. However, they <font color='red'>**do not**</font> provide **information about the range of the QOI**.\n",
    "\n",
    "A **confidence interval** $\\mathcal{I}(p)\\subseteq \\mathbb{R}$ is linked to a confidence level $p\\in [0,1]$ which expresses the probability of $\\mathcal{I}(p)$ to contain the true QOI.\n",
    "\n",
    "## **Outline**\n",
    "- Confidence interval of the **expectation** using the Central Limit Theorem (for large $n$) and Student's $t$-distribution (for low and moderate $n$)\n",
    "- Confidence interval of the **variance** using the $\\chi^2$ distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import functions for accessing Student's t-distribution and the normal distribution\n",
    "from scipy.stats import t as t_dist\n",
    "from scipy.stats import norm as norm_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Confidence interval estimation for $E(Y)$**\n",
    "The MLE estimator for the expectation is the sample mean $$\\overline{y}=\\frac{1}{n} \\sum_{i=1}^n y_i.$$\n",
    "Two cases must be distinguished for interval estimation:\n",
    "- low to moderate number of samples (in general $n<30$ for a single RV)\n",
    "- high sample count ($n>30$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **High sample count** ($n>30$)\n",
    "The Central Limit Theorem can be assumed to hold if a sufficient number of samples is available. Then\n",
    "$$\\overline{y} \\sim \\mathcal{N} \\left( E(Y_1), \\frac{\\sigma_y^2}{n} \\right), \\qquad \\sigma_y^2 \\approx \\sigma^2 = \\frac{1}{n-1} \\sum_{i=1}^n ( y_i - \\overline{y}_i )^2$$\n",
    "Using the inverse distribution function $F^{-1}(p)$ of the standard normal distribution one obtains\n",
    "$$\\Delta = F^{-1} \\left( \\frac{1+p}{2} \\right) \\frac{\\sigma_n}{\\sqrt{n}} \\qquad \\mathcal{I}(p) =  \\left( \\overline{y}_n-\\Delta, \\overline{y}_n+\\Delta \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 1: uniformly random samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range for data .................. [-0.20,  1.75]\n",
      "number of samples ...............         10\n",
      "ybar ............................    0.94127\n",
      "E(y) (true value) ...............    0.77345\n",
      "sigma_y (analytical) ............    0.56148\n",
      "sigma_n (estimated) .............    0.74063\n",
      "sigma_ybar ......................    0.23421\n",
      "confidence level ................    0.92500\n",
      "Delta ...........................    0.41700   (=  1.78046 * sigma_ybar =  0.56303 * sigma)\n"
     ]
    }
   ],
   "source": [
    "n       = 10\n",
    "LB      = np.random.uniform(-1,1, size=1)\n",
    "UB      = np.random.uniform(1, 5, size=1) + LB\n",
    "\n",
    "# theoretical results for the underlying distribution:\n",
    "sigma_y = np.sqrt( (UB-LB)**2/12 )\n",
    "EY      = (UB+LB)/2\n",
    "\n",
    "# generate random data\n",
    "y       = np.random.uniform( LB, UB, size=n )\n",
    "\n",
    "# estimate ybar and sigma\n",
    "ybar    = np.sum(y)/n\n",
    "sigma   = np.sqrt(np.sum((y-ybar)**2)/(n-1))\n",
    "sigma_ybar = sigma / np.sqrt(n)\n",
    "\n",
    "# confidence level\n",
    "p       = 0.925\n",
    "q       = (1.0+p)/2.0\n",
    "\n",
    "Delta   = norm_dist.ppf(q) * sigma_ybar\n",
    "\n",
    "print('range for data .................. [%5.2f, %5.2f]' % (LB, UB))\n",
    "print('number of samples ............... %10d' % n)\n",
    "print('ybar ............................ %10.5f' % ybar )\n",
    "print('E(y) (true value) ............... %10.5f' % (EY) )\n",
    "print('sigma_y (analytical) ............ %10.5f' % ( sigma_y ) )\n",
    "print('sigma_n (estimated) ............. %10.5f' % sigma )\n",
    "print('sigma_ybar ...................... %10.5f' % sigma_ybar )\n",
    "print('confidence level ................ %10.5f' % p )\n",
    "print('Delta ........................... %10.5f   (= %8.5f * sigma_ybar = %8.5f * sigma)' % ( Delta, Delta/sigma_ybar, Delta/sigma) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Remarks*\n",
    "- the width $w=2\\Delta$ of $\\mathcal{I}(p)$ scales with $\\sigma_y/\\sqrt{n}$\n",
    "- the estimator $\\sigma$ for $\\sigma_y$ should be unbiased (although the difference to the MLE estimator is negligible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Low/moderate sample counts $(n \\leq 30)$**\n",
    "\n",
    "For lower sampel counts Student's $t$-distribution is used. We set $\\nu=n-1$ and obtain\n",
    "$$\\Delta = F_t^{-1} \\left( \\frac{1+p}{2} \\, \\Big\\vert \\, \\nu \\right) \\frac{\\sigma_n}{\\sqrt{n}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu = n-1\n",
    "Delta_t = t_dist(nu).ppf(q) * sigma_n/np.sqrt(n)\n",
    "print('Delta (CLT) vs. Delta (Student\\'s t-distribution): %10.5f  /  %10.5f  /  ratio: %10.5f ' \\\n",
    "      % ( Delta, Delta_t, Delta/Delta_t ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- $\\Delta < \\Delta_t$\n",
    "- $\\underset{n\\to \\infty}{\\text{lim}} \\Delta_t-\\Delta \\to 0$\n",
    "- the higher $p$, the bigger the difference in $\\Delta$ and $\\Delta_t$ *(but small quantitative difference)*\n",
    "- ratios for some $n$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = np.array([5,10,30,100])\n",
    "P = np.array([0.9,0.925,0.95,0.975,0.995])\n",
    "for p in P:\n",
    "    q=(1+p)/2\n",
    "    print('confidence level:   %6.3f%%' % (100*p) )\n",
    "    for n in N:\n",
    "        print('n = %3d  --> ratio:  %6.4f' % ( n, norm_dist.ppf(q)/t_dist(n-1).ppf(q)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
